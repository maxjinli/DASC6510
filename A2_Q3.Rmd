---
title: "DS6510 A2 Q3"
author: "Max Li"
date: "2024-03-28"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(ISLR)
library(dplyr)
library(tidyr)
library(coda)
library(reshape)
library(stats4)
library(MCMCpack)
library(ggplot2)
library(MASS)
library(Matrix)
library(knitr)
```

# Question 3: 

Logistic regression variable selection: Consider a logistic regression model for predicting diabetes as a function of $x_1 =$ number of pregnancies, $x_2 =$ blood pressure, $x_3 =$ body mass index, $x_4 =$ diabetes pedigree and $x_5 =$ age. Using the data in `azdiabetes.dat`, center and scale each of the $x-$variables by subtracting the sample average and dividing by the sample standard deviation for each variable. Consider a logistic regression model of the form $\Pr(Y_i =1 \mid x_i,\beta,z) = e^{\theta_i}/(1+e^{\theta_i})$ where
$$
\theta_i = \beta_0 + \beta_1\gamma_1x_{i,1} + \beta_2\gamma_2x_{i,2} ++ \beta_3\gamma_3x_{i,3} + \beta_4\gamma_4x_{i,4} + \beta_5\gamma_5x_{i,5}
$$
In this model, each $\gamma-j$ is either 0 or 1, indicating whether or not variable $j$ is a predictor of diabetes. For example, if it were the case that $\gamma = (1, 1, 0, 0, 0)$, then $\theta_i = \beta_0 + \beta_1x_{i,1} + \beta_2x_{i,2}$. Obtain posterior distributions for $\beta$ and $\gamma$, using independent prior distributions for the parameters, such that $\gamma_j \sim binary(1/2)$, $\beta_0 \sim normal(0, 16)$ and $\beta_j \sim normal(0, 4)$ for each $j > 0$.\newline

a) Implement a Metropolis-Hastings algorithm for approximating the posterior distribution of $\beta$ and $\gamma$. Examine the sequences $\beta^{(s)}_j$ and
$\beta^{(s)}_j \times \gamma^{(s)}_j$ for each j and discuss the mixing of the chain.\newline

```{r, indent = "     "}
data = read.table("azdiabetes.dat", header = TRUE, stringsAsFactors = FALSE)
y = (data[,8]=='Yes')*1
X = data[,c('npreg', 'bp', 'bmi', 'ped', 'age')] %>% as.matrix() %>% scale()
logit = function(p) {log(p/(1-p))} 
expit = function(x) {exp(x)/(1+exp(x))}
# need this fix function for situation like:
# 0 = log(0^0) = 0*log(0) producing NaN and NA 
fix = function(x) {
ind = is.nan(x)|is.na(x) 
x[ind] = 0
x
}
update_beta0 = function(gamma, beta, beta0) {
  beta0_p = rnorm(1, beta0, sd = 2) # propose beta0
  pi = expit(beta0 + as.matrix(X[,gamma==1]) %*% beta[gamma==1]) # pi_original
  pi_p = expit(beta0_p + as.matrix(X[,gamma==1]) %*% beta[gamma==1]) # pi_proposed
  log_a = sum(fix(y*log(pi_p))+fix((1-y)*log(1-pi_p))) + dnorm(beta0_p, mean=0, sd=4, log=TRUE) 
  log_b = sum(fix(y*log(pi))+fix((1-y)*log(1-pi))) + dnorm(beta0, mean=0, sd=4, log=TRUE) 
  log_r = log_a - log_b
u = runif(1)
beta0_new = ifelse(log(u)<log_r, beta0_p, beta0)
return(beta0_new)
}

update_beta = function(gamma, beta, beta0) {
  p = length(beta)
# for code simplicity, treat beta_gamma, beta_{-gamma} as the same 
  for(j in 1:p) {
    beta_p = beta
    beta_p[j] = rnorm(1, beta[j], sd = 1) # proposal beta
    pi = expit(beta0 + as.matrix(X[,gamma==1]) %*% beta[gamma==1]) # pi_original
    pi_p = expit(beta0 + as.matrix(X[,gamma==1]) %*% beta_p[gamma==1]) # pi_proposed
    log_a = sum(fix(y*log(pi_p))+fix((1-y)*log(1-pi_p))) + dnorm(beta_p[j], mean=0, sd=2, log=TRUE)
    log_b = sum(fix(y*log(pi))+fix((1-y)*log(1-pi))) + dnorm(beta[j], mean=0, sd=2, log=TRUE) 
    log_r = log_a - log_b
    log_r
    u = runif(1)
    beta[j] = ifelse(log(u)<log_r, beta_p[j], beta[j])
  }
  return(beta) 
}

update_gamma = function(gamma, beta, beta0) {
  # randomly choose update order
  p = length(gamma) 
  for(j in sample(p)) {
    gamma_a = gamma_b = gamma 
    gamma_a[j] = 1 # for numerator 
    gamma_b[j] = 0 # for denominator
    pi_a = expit(beta0 + as.matrix(X[,gamma_a==1]) %*% beta[gamma_a==1]) # pi_original 
    log_a = sum(fix(y*log(pi_a))+fix((1-y)*log(1-pi_a)))# log numerator
    pi_b = expit(beta0 + as.matrix(X[,gamma_b==1]) %*% beta[gamma_b==1]) # pi_original 
    log_b = sum(fix(y*log(pi_b))+fix((1-y)*log(1-pi_b)))# log numerator
    log_odds = log_a - log_b
    u = runif(1)
    gamma[j] = ifelse(u < expit(log_odds), 1, 0)
  }
  return(gamma) 
}

# initial values
p=5
gamma = rep(1, p)
beta = rep(0, p)
beta0 = 1
S = 10300
B = 300 # Burn-in
Gamma = matrix(NA, nrow = S, ncol = p) 
Beta = matrix(NA, nrow = S, ncol = p) 
Beta0 = rep(NA, S)

# update parameters
for(i in 1:S) {
beta0 = update_beta0(gamma, beta, beta0) 
beta = update_beta(gamma, beta, beta0) 
gamma = update_gamma(gamma, beta, beta0) 
Beta0[i] = beta0
Beta[i,] = beta
Gamma[i,] = gamma
# print(i)
}

Beta0 = Beta0[-(1:B)]
Beta = Beta[-(1:B),]
Gamma = Gamma[-(1:B),]
```


```{r}
par(mfrow=c(3, 2), mar=c(4, 4, 2, 1)) 
plot(Beta0, type = 'l', main = 'traceplot for beta0') 
plot(Beta[,1], type = 'l', main = 'traceplot for beta1') 
plot(Beta[,2], type = 'l', main = 'traceplot for beta2') 
plot(Beta[,3], type = 'l', main = 'traceplot for beta3') 
plot(Beta[,4], type = 'l', main = 'traceplot for beta4') 
plot(Beta[,5], type = 'l', main = 'traceplot for beta5')

BG = Beta * Gamma
par(mfrow=c(3, 2), mar=c(4, 4, 2, 1)) 
plot(BG[,1], type = 'l', main = 'traceplot for beta1 * gamma1') 
plot(BG[,2], type = 'l', main = 'traceplot for beta2 * gamma2') 
plot(BG[,3], type = 'l', main = 'traceplot for beta3 * gamma3') 
plot(BG[,4], type = 'l', main = 'traceplot for beta4 * gamma4') 
plot(BG[,5], type = 'l', main = 'traceplot for beta5 * gamma5')

res = rbind(apply(Beta, 2, effectiveSize), 
            apply(BG, 2, effectiveSize))
rownames(res) = c('beta', 'beta \\* gamma') 
res %>%
  kable(col.names = 1:5,
        caption = 'Effective Sample Size out of 10000')
```
```



